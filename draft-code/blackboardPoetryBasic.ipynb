{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lynnyang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import brown\n",
    "import tkinter as tk\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blackboard:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.window = tk.Tk()\n",
    "        # set the tk window unchangeable;\n",
    "        self.window.resizable(False,False)\n",
    "        self.canvas = tk.Canvas(self.window,width=1000,height=1000)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.lines = []\n",
    "        self.lines.append([random.randint(10,400),random.randint(10,450), \\\n",
    "                           \"Once there was a dog and a cat\",\"l0\"])\n",
    "        self.lines.append([random.randint(10,400),random.randint(10,450), \\\n",
    "                           \"Who decided to have an extended natter\",\"l1\"])\n",
    "        # self.lines.append([random.randint(10,400),random.randint(10,450), \\\n",
    "        #                    \"It's the best part of the day, morning light sliding\", \\\n",
    "        #                    \"l2\"])\n",
    "        # self.lines.append([random.randint(10,400),random.randint(10,450), \\\n",
    "        #                    \"down rooftops, treetops, the birds pulling themselves\", \\\n",
    "        #                    \"l3\"])\n",
    "        # self.lines.append([random.randint(10,400),random.randint(10,450), \\\n",
    "        #                    \"up out of whatever stupor darkened their wings\", \\\n",
    "        #                    \"l4\"])\n",
    "        # self.lines.append([random.randint(10,400),random.randint(10,450), \\\n",
    "        #                    \"night still in their throats\", \\\n",
    "        #                    \"l5\"])\n",
    "        # # lines from a poem by Dorianne Laux\n",
    "\n",
    "        for ll in self.lines:\n",
    "        #   create text line at postion x=ll[0], y=ll[1], text content is ll[2]\n",
    "#         and give it a tag to label it. anchor w means align with leftside.\n",
    "            self.canvas.create_text(ll[0],ll[1],text=ll[2],tags=ll[3], anchor=tk.W)\n",
    "#         self.agentList = [removeAdjective, makeTwoLinesRhyme]\n",
    "        \n",
    "    def run(self):\n",
    "        print(\"*** in run\")\n",
    "        ag = random.choice(self.agentList)\n",
    "        self.lines = ag(self.lines)\n",
    "\n",
    "#       delete the entire canvas.\n",
    "        self.canvas.delete(\"all\")\n",
    "    \n",
    "        for ll in self.lines:\n",
    "            self.canvas.create_text(ll[0],ll[1],text=ll[2],tags=ll[3],anchor=tk.W)\n",
    "        self.canvas.after(1000,Blackboard.run,self)\n",
    "\n",
    "    def main(self):\n",
    "        self.run()\n",
    "        self.window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeAdjective(lines):\n",
    "    ll = lines.pop(random.randrange(len(lines)))\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(ll[2]))\n",
    "    adjList = []\n",
    "    for idx,val in enumerate(tagged):\n",
    "        if val[1]==\"JJ\":\n",
    "            adjList.append(idx)\n",
    "    print(\"Adjective List is \",adjList)\n",
    "    if adjList:\n",
    "        del tagged[random.choice(adjList)]\n",
    "    newLine = \" \".join([ x[0] for x in tagged ])\n",
    "    #print(newLine)\n",
    "    lines.append([ll[0],ll[1],newLine,ll[3]])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTwoLinesRhyme(lines):\n",
    "    ll1 = lines.pop(random.randrange(len(lines)))\n",
    "    ll2 = lines.pop(random.randrange(len(lines)))\n",
    "    lastWord1 = nltk.word_tokenize(ll1[2])[-1]\n",
    "    lastWord2 = nltk.word_tokenize(ll2[2])[-1]\n",
    "    entries = nltk.corpus.cmudict.entries()\n",
    "    syllables = [(word, syl) for word, syl in entries if word == lastWord1]\n",
    "    rhymes = []\n",
    "    #level = random.randrange(1,3)\n",
    "    level = 2\n",
    "    for (word, syllable) in syllables:\n",
    "        rhymes += [word for word, pronunciation in entries \\\n",
    "                   if pronunciation[-level:] == syllable[-level:]]\n",
    "    print(\"rhymes with \",lastWord1)\n",
    "    print(rhymes[0:10])\n",
    "\n",
    "    if rhymes:\n",
    "        newTokens = list(nltk.word_tokenize(ll2[2])[:-1])\n",
    "        newTokens.append(random.choice(rhymes))\n",
    "        newLine = \" \".join(newTokens)\n",
    "        lines.append([ll1[0],ll1[1],ll1[2],ll1[3]])\n",
    "        if random.random()<0.5:\n",
    "            lines.append([ll1[0],ll1[1]+20,newLine,ll2[3]])\n",
    "        else:\n",
    "            lines.append([ll1[0],ll1[1]-20,newLine,ll2[3]])\n",
    "    else:\n",
    "        lines.append(ll1)\n",
    "        lines.append(ll2)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceWithSynonym(lines):\n",
    "    ll = lines.pop(random.randrange(len(lines)))\n",
    "    tokens = nltk.word_tokenize(ll[2])\n",
    "    wordIdx = random.randrange(len(tokens))\n",
    "    wordToBeReplaced = tokens[wordIdx]\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(wordToBeReplaced):\n",
    "        for l in syn.lemmas():\n",
    "            if not \"_\" in l.name():\n",
    "                synonyms.append(l.name())\n",
    "    if synonyms:\n",
    "        tokens[wordIdx] = random.choice(synonyms)\n",
    "    else:\n",
    "        tokens[wordIdx] = wordToBeReplaced\n",
    "    newLine = \" \".join(tokens)\n",
    "    lines.append([ll[0],ll[1],newLine,ll[3]])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSensibleAdjective(lines):\n",
    "    originalLines = copy.deepcopy(lines)\n",
    "    ll = lines.pop(random.randrange(len(lines)))\n",
    "\n",
    "    ## add lines here that:\n",
    "    # tokenise ll[2], and store this in a variable called tokenized\n",
    "    # part-of-speech tag the tokenized list, store this in a variable called tagged\n",
    "    # find the positions of nouns in the list\n",
    "    # if there are no nouns, return originalLines\n",
    "    # choose a random noun, store this in a variable called chosenNoun\n",
    "    # store the position of that noun in the list (its index) in a variable called chosenNounPosition\n",
    "\n",
    "    ##now add the adjective\n",
    "    bigrams = ngrams(brown.words(), 2)\n",
    "    preWords = [ bg[0] for bg in bigrams if bg[1]==chosenNoun ]\n",
    "    taggedPreWords = nltk.pos_tag(preWords)\n",
    "    chosenPreWords = [ pw[0] for pw in taggedPreWords if (pw[1]==\"JJ\") ]\n",
    "    #You can also experiment with checking for VBN or NN\n",
    "    if not chosenPreWords:\n",
    "        return originalLines\n",
    "    chosenDescriptor = random.choice(chosenPreWords)\n",
    "    tokenized.insert(chosenNounPosition, chosenDescriptor)\n",
    "    newLine = \" \".join(tokenized)\n",
    "    lines.append([ll[0],ll[1],newLine,ll[3]])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** in run\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mcmudict\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('cmudict')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/cmudict\u001b[0m\n\n  Searched in:\n    - '/Users/lynnyang/nltk_data'\n    - '/Users/lynnyang/opt/anaconda3/envs/DIA/nltk_data'\n    - '/Users/lynnyang/opt/anaconda3/envs/DIA/share/nltk_data'\n    - '/Users/lynnyang/opt/anaconda3/envs/DIA/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/DIA/lib/python3.10/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DIA/lib/python3.10/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mcmudict\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('cmudict')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/cmudict.zip/cmudict/\u001b[0m\n\n  Searched in:\n    - '/Users/lynnyang/nltk_data'\n    - '/Users/lynnyang/opt/anaconda3/envs/DIA/nltk_data'\n    - '/Users/lynnyang/opt/anaconda3/envs/DIA/share/nltk_data'\n    - '/Users/lynnyang/opt/anaconda3/envs/DIA/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m bb \u001b[38;5;241m=\u001b[39m Blackboard()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mbb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mBlackboard.main\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mBlackboard.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** in run\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m ag \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magentList)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines \u001b[38;5;241m=\u001b[39m \u001b[43mag\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdelete(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ll \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines:\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mmakeTwoLinesRhyme\u001b[0;34m(lines)\u001b[0m\n\u001b[1;32m      4\u001b[0m lastWord1 \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(ll1[\u001b[38;5;241m2\u001b[39m])[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m lastWord2 \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(ll2[\u001b[38;5;241m2\u001b[39m])[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcmudict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentries\u001b[49m()\n\u001b[1;32m      7\u001b[0m syllables \u001b[38;5;241m=\u001b[39m [(word, syl) \u001b[38;5;28;01mfor\u001b[39;00m word, syl \u001b[38;5;129;01min\u001b[39;00m entries \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;241m==\u001b[39m lastWord1]\n\u001b[1;32m      8\u001b[0m rhymes \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DIA/lib/python3.10/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DIA/lib/python3.10/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DIA/lib/python3.10/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DIA/lib/python3.10/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mcmudict\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('cmudict')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/cmudict\u001b[0m\n\n  Searched in:\n    - '/Users/lynnyang/nltk_data'\n    - '/Users/lynnyang/opt/anaconda3/envs/DIA/nltk_data'\n    - '/Users/lynnyang/opt/anaconda3/envs/DIA/share/nltk_data'\n    - '/Users/lynnyang/opt/anaconda3/envs/DIA/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "bb = Blackboard()\n",
    "bb.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
